{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our dataset format\n",
    "An event is a list of strings.\n",
    "\n",
    "A sequence is a list of events.\n",
    "\n",
    "A dataset is a list of sequences.\n",
    "\n",
    "Thus, a dataset is a list of lists of lists of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/admin-user/swardi/drone-seq-mining\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ï»¿dataset</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>message</th>\n",
       "      <th>element_id</th>\n",
       "      <th>event_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>df010</td>\n",
       "      <td>6/29/2017</td>\n",
       "      <td>14:52:06</td>\n",
       "      <td>2</td>\n",
       "      <td>Taking Off</td>\n",
       "      <td>4</td>\n",
       "      <td>e1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>df010</td>\n",
       "      <td>6/29/2017</td>\n",
       "      <td>14:52:08</td>\n",
       "      <td>2</td>\n",
       "      <td>Taking Off</td>\n",
       "      <td>4</td>\n",
       "      <td>e1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>df010</td>\n",
       "      <td>6/29/2017</td>\n",
       "      <td>14:52:09</td>\n",
       "      <td>2</td>\n",
       "      <td>Home Point Recorded. RTH Altitude:Â  30m.</td>\n",
       "      <td>4</td>\n",
       "      <td>e2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>df010</td>\n",
       "      <td>6/29/2017</td>\n",
       "      <td>15:02:26</td>\n",
       "      <td>2</td>\n",
       "      <td>Obstacle Avoided. Revise Flight Route</td>\n",
       "      <td>4</td>\n",
       "      <td>e12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>df010</td>\n",
       "      <td>6/29/2017</td>\n",
       "      <td>15:24:31</td>\n",
       "      <td>1</td>\n",
       "      <td>Taking Off</td>\n",
       "      <td>1</td>\n",
       "      <td>e1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>df082</td>\n",
       "      <td>11/20/2018</td>\n",
       "      <td>11:27:47 PM</td>\n",
       "      <td>29</td>\n",
       "      <td>Switched to P (Positioning)-mode.</td>\n",
       "      <td>64</td>\n",
       "      <td>e66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>df082</td>\n",
       "      <td>11/20/2018</td>\n",
       "      <td>11:27:47 PM</td>\n",
       "      <td>29</td>\n",
       "      <td>Switched to S (Sport)-mode.</td>\n",
       "      <td>64</td>\n",
       "      <td>e68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>df082</td>\n",
       "      <td>11/20/2018</td>\n",
       "      <td>11:27:53 PM</td>\n",
       "      <td>29</td>\n",
       "      <td>GEO: You are in a Warning Zone (School). Fly w...</td>\n",
       "      <td>64</td>\n",
       "      <td>e65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>df082</td>\n",
       "      <td>11/20/2018</td>\n",
       "      <td>11:28:22 PM</td>\n",
       "      <td>29</td>\n",
       "      <td>Tip: Aircraft reached maximum distance, please...</td>\n",
       "      <td>64</td>\n",
       "      <td>e71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>df082</td>\n",
       "      <td>11/20/2018</td>\n",
       "      <td>11:29:04 PM</td>\n",
       "      <td>29</td>\n",
       "      <td>Tip: Aircraft reached maximum distance, please...</td>\n",
       "      <td>64</td>\n",
       "      <td>e71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>389 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ï»¿dataset        date         time  sequence_id  \\\n",
       "0        df010   6/29/2017     14:52:06            2   \n",
       "1        df010   6/29/2017     14:52:08            2   \n",
       "2        df010   6/29/2017     14:52:09            2   \n",
       "3        df010   6/29/2017     15:02:26            2   \n",
       "4        df010   6/29/2017     15:24:31            1   \n",
       "..         ...         ...          ...          ...   \n",
       "384      df082  11/20/2018  11:27:47 PM           29   \n",
       "385      df082  11/20/2018  11:27:47 PM           29   \n",
       "386      df082  11/20/2018  11:27:53 PM           29   \n",
       "387      df082  11/20/2018  11:28:22 PM           29   \n",
       "388      df082  11/20/2018  11:29:04 PM           29   \n",
       "\n",
       "                                               message  element_id event_id  \n",
       "0                                           Taking Off           4       e1  \n",
       "1                                           Taking Off           4       e1  \n",
       "2            Home Point Recorded. RTH Altitude:Â  30m.           4       e2  \n",
       "3                Obstacle Avoided. Revise Flight Route           4      e12  \n",
       "4                                           Taking Off           1       e1  \n",
       "..                                                 ...         ...      ...  \n",
       "384                  Switched to P (Positioning)-mode.          64      e66  \n",
       "385                        Switched to S (Sport)-mode.          64      e68  \n",
       "386  GEO: You are in a Warning Zone (School). Fly w...          64      e65  \n",
       "387  Tip: Aircraft reached maximum distance, please...          64      e71  \n",
       "388  Tip: Aircraft reached maximum distance, please...          64      e71  \n",
       "\n",
       "[389 rows x 7 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "import pandas as pd\n",
    "dataset_path = './sequence_db.csv'\n",
    "# data_test_path = '/content/drive/MyDrive/Colab Notebooks/ner-drone/ner_drone_test_2.csv'\n",
    "dataset = pd.read_csv(dataset_path, encoding= 'unicode_escape')\n",
    "# dataset_test = pd.read_csv(data_test_path, encoding= 'unicode_escape')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>element_id</th>\n",
       "      <th>event_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>e1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>e1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>e2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>e12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>e1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>29</td>\n",
       "      <td>64</td>\n",
       "      <td>e66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>29</td>\n",
       "      <td>64</td>\n",
       "      <td>e68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>29</td>\n",
       "      <td>64</td>\n",
       "      <td>e65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>29</td>\n",
       "      <td>64</td>\n",
       "      <td>e71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>29</td>\n",
       "      <td>64</td>\n",
       "      <td>e71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>389 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sequence_id  element_id event_id\n",
       "0              2           4       e1\n",
       "1              2           4       e1\n",
       "2              2           4       e2\n",
       "3              2           4      e12\n",
       "4              1           1       e1\n",
       "..           ...         ...      ...\n",
       "384           29          64      e66\n",
       "385           29          64      e68\n",
       "386           29          64      e65\n",
       "387           29          64      e71\n",
       "388           29          64      e71\n",
       "\n",
       "[389 rows x 3 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_db = dataset[['sequence_id', 'element_id', 'event_id']]\n",
    "sequence_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_db_sorted = sequence_db.sort_values(['sequence_id'], ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>element_id</th>\n",
       "      <th>event_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>e10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>e7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>e7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>e7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>e4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>29</td>\n",
       "      <td>61</td>\n",
       "      <td>e65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>29</td>\n",
       "      <td>61</td>\n",
       "      <td>e41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>29</td>\n",
       "      <td>64</td>\n",
       "      <td>e71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>29</td>\n",
       "      <td>63</td>\n",
       "      <td>e41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>29</td>\n",
       "      <td>64</td>\n",
       "      <td>e71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>389 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sequence_id  element_id event_id\n",
       "30             1           3      e10\n",
       "20             1           2       e7\n",
       "21             1           2       e7\n",
       "22             1           2       e7\n",
       "23             1           2       e4\n",
       "..           ...         ...      ...\n",
       "365           29          61      e65\n",
       "364           29          61      e41\n",
       "387           29          64      e71\n",
       "375           29          63      e41\n",
       "388           29          64      e71\n",
       "\n",
       "[389 rows x 3 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_db_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>element_id</th>\n",
       "      <th>event_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[e1, e1, e1, e1, e2, e2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[e7, e7, e7, e4, e8, e4, e7, e8, e9, e6, e5, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[e10, e1, e1, e1, e1, e1, e1, e11, e2, e2, e1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>[e1, e12, e2, e1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>[e13, e14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>28</td>\n",
       "      <td>60</td>\n",
       "      <td>[e65, e41, e68, e70, e66, e66, e71, e42]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>29</td>\n",
       "      <td>61</td>\n",
       "      <td>[e66, e53, e65, e68, e66, e2, e42, e65, e41]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>29</td>\n",
       "      <td>62</td>\n",
       "      <td>[e66, e68]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>29</td>\n",
       "      <td>63</td>\n",
       "      <td>[e68, e65, e2, e42, e41]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>29</td>\n",
       "      <td>64</td>\n",
       "      <td>[e41, e42, e66, e66, e68, e65, e70, e71, e71]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sequence_id  element_id                                           event_id\n",
       "0             1           1                           [e1, e1, e1, e1, e2, e2]\n",
       "1             1           2  [e7, e7, e7, e4, e8, e4, e7, e8, e9, e6, e5, e...\n",
       "2             1           3  [e10, e1, e1, e1, e1, e1, e1, e11, e2, e2, e1,...\n",
       "3             2           4                                  [e1, e12, e2, e1]\n",
       "4             3           5                                         [e13, e14]\n",
       "..          ...         ...                                                ...\n",
       "59           28          60           [e65, e41, e68, e70, e66, e66, e71, e42]\n",
       "60           29          61       [e66, e53, e65, e68, e66, e2, e42, e65, e41]\n",
       "61           29          62                                         [e66, e68]\n",
       "62           29          63                           [e68, e65, e2, e42, e41]\n",
       "63           29          64      [e41, e42, e66, e66, e68, e65, e70, e71, e71]\n",
       "\n",
       "[64 rows x 3 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_db_grouped = sequence_db_sorted.groupby(['sequence_id','element_id'], as_index=False)['event_id'].agg(lambda x: list(x))\n",
    "sequence_db_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "print(len(sequence_db_grouped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[['e1', 'e1', 'e1', 'e1', 'e2', 'e2']]\n",
      "[['e1', 'e1', 'e1', 'e1', 'e2', 'e2'], ['e7', 'e7', 'e7', 'e4', 'e8', 'e4', 'e7', 'e8', 'e9', 'e6', 'e5', 'e6', 'e4', 'e5', 'e5', 'e6', 'e7', 'e7']]\n",
      "[['e1', 'e1', 'e1', 'e1', 'e2', 'e2'], ['e7', 'e7', 'e7', 'e4', 'e8', 'e4', 'e7', 'e8', 'e9', 'e6', 'e5', 'e6', 'e4', 'e5', 'e5', 'e6', 'e7', 'e7'], ['e10', 'e1', 'e1', 'e1', 'e1', 'e1', 'e1', 'e11', 'e2', 'e2', 'e1', 'e1']]\n",
      "2\n",
      "[['e1', 'e12', 'e2', 'e1']]\n",
      "3\n",
      "[['e13', 'e14']]\n",
      "[['e13', 'e14'], ['e17']]\n",
      "[['e13', 'e14'], ['e17'], ['e18', 'e18', 'e15', 'e16']]\n",
      "4\n",
      "[['e36', 'e1', 'e1', 'e2', 'e11', 'e23', 'e1', 'e2', 'e1']]\n",
      "[['e36', 'e1', 'e1', 'e2', 'e11', 'e23', 'e1', 'e2', 'e1'], ['e11', 'e35', 'e38', 'e21', 'e11', 'e37']]\n",
      "[['e36', 'e1', 'e1', 'e2', 'e11', 'e23', 'e1', 'e2', 'e1'], ['e11', 'e35', 'e38', 'e21', 'e11', 'e37'], ['e1', 'e2', 'e39', 'e30', 'e30', 'e30', 'e30', 'e36', 'e11', 'e35', 'e1', 'e11', 'e30']]\n",
      "5\n",
      "[['e39', 'e2', 'e1', 'e1']]\n",
      "[['e39', 'e2', 'e1', 'e1'], ['e39', 'e37', 'e11', 'e21', 'e39', 'e23', 'e40', 'e29', 'e29']]\n",
      "6\n",
      "[['e11', 'e12', 'e39', 'e1', 'e1', 'e2']]\n",
      "7\n",
      "[['e2', 'e20', 'e1', 'e23', 'e22', 'e20', 'e11', 'e21', 'e1', 'e2']]\n",
      "[['e2', 'e20', 'e1', 'e23', 'e22', 'e20', 'e11', 'e21', 'e1', 'e2'], ['e24', 'e25', 'e24']]\n",
      "[['e2', 'e20', 'e1', 'e23', 'e22', 'e20', 'e11', 'e21', 'e1', 'e2'], ['e24', 'e25', 'e24'], ['e23', 'e22', 'e20', 'e11']]\n",
      "8\n",
      "[['e20', 'e2', 'e1', 'e1']]\n",
      "[['e20', 'e2', 'e1', 'e1'], ['e29', 'e27', 'e26']]\n",
      "[['e20', 'e2', 'e1', 'e1'], ['e29', 'e27', 'e26'], ['e30']]\n",
      "[['e20', 'e2', 'e1', 'e1'], ['e29', 'e27', 'e26'], ['e30'], ['e23', 'e22', 'e20', 'e11', 'e24', 'e18', 'e31', 'e31']]\n",
      "9\n",
      "[['e1', 'e1', 'e2', 'e20']]\n",
      "[['e1', 'e1', 'e2', 'e20'], ['e23', 'e20', 'e22', 'e11', 'e36', 'e11', 'e34', 'e22', 'e35', 'e34', 'e11', 'e22', 'e20', 'e20']]\n",
      "[['e1', 'e1', 'e2', 'e20'], ['e23', 'e20', 'e22', 'e11', 'e36', 'e11', 'e34', 'e22', 'e35', 'e34', 'e11', 'e22', 'e20', 'e20'], ['e1', 'e23', 'e2', 'e20', 'e32', 'e32', 'e30', 'e21', 'e11', 'e20', 'e22', 'e33', 'e1']]\n",
      "10\n",
      "[['e29', 'e29', 'e29', 'e29', 'e11', 'e29', 'e29', 'e2', 'e29']]\n",
      "11\n",
      "[['e43', 'e43', 'e43', 'e43', 'e43', 'e2']]\n",
      "[['e43', 'e43', 'e43', 'e43', 'e43', 'e2'], ['e24', 'e31', 'e11']]\n",
      "[['e43', 'e43', 'e43', 'e43', 'e43', 'e2'], ['e24', 'e31', 'e11'], ['e2']]\n",
      "[['e43', 'e43', 'e43', 'e43', 'e43', 'e2'], ['e24', 'e31', 'e11'], ['e2'], ['e44', 'e44', 'e44', 'e44', 'e44', 'e44', 'e44', 'e44', 'e44', 'e44', 'e44', 'e24', 'e44', 'e44', 'e44', 'e44', 'e44', 'e44', 'e24', 'e44', 'e24', 'e44', 'e44', 'e45', 'e2', 'e24', 'e44', 'e44', 'e24', 'e44', 'e44', 'e44', 'e44', 'e44', 'e44', 'e44', 'e44']]\n",
      "[['e43', 'e43', 'e43', 'e43', 'e43', 'e2'], ['e24', 'e31', 'e11'], ['e2'], ['e44', 'e44', 'e44', 'e44', 'e44', 'e44', 'e44', 'e44', 'e44', 'e44', 'e44', 'e24', 'e44', 'e44', 'e44', 'e44', 'e44', 'e44', 'e24', 'e44', 'e24', 'e44', 'e44', 'e45', 'e2', 'e24', 'e44', 'e44', 'e24', 'e44', 'e44', 'e44', 'e44', 'e44', 'e44', 'e44', 'e44'], ['e24', 'e11']]\n",
      "12\n",
      "[['e48', 'e41', 'e42']]\n",
      "13\n",
      "[['e48', 'e41', 'e48', 'e41', 'e42', 'e2', 'e49', 'e46']]\n",
      "[['e48', 'e41', 'e48', 'e41', 'e42', 'e2', 'e49', 'e46'], ['e46', 'e46', 'e46', 'e46', 'e46', 'e46']]\n",
      "14\n",
      "[['e21', 'e41', 'e42', 'e1']]\n",
      "15\n",
      "[['e30', 'e30', 'e2', 'e2']]\n",
      "16\n",
      "[['e1']]\n",
      "[['e1'], ['e32', 'e27', 'e36']]\n",
      "17\n",
      "[['e42', 'e41']]\n",
      "[['e42', 'e41'], ['e47', 'e50', 'e51']]\n",
      "[['e42', 'e41'], ['e47', 'e50', 'e51'], ['e52', 'e50', 'e47']]\n",
      "18\n",
      "[['e41', 'e42', 'e39']]\n",
      "[['e41', 'e42', 'e39'], ['e53', 'e52']]\n",
      "19\n",
      "[['e57', 'e56', 'e55', 'e42', 'e41']]\n",
      "[['e57', 'e56', 'e55', 'e42', 'e41'], ['e56', 'e16', 'e15', 'e52', 'e56', 'e56', 'e58']]\n",
      "20\n",
      "[['e2', 'e20']]\n",
      "[['e2', 'e20'], ['e20', 'e56']]\n",
      "21\n",
      "[['e36', 'e24', 'e24', 'e24', 'e24', 'e24']]\n",
      "22\n",
      "[['e61', 'e36', 'e57', 'e61', 'e57', 'e61', 'e61', 'e60', 'e60', 'e42', 'e59', 'e1', 'e41', 'e57']]\n",
      "23\n",
      "[['e64', 'e64', 'e2', 'e39', 'e39']]\n",
      "24\n",
      "[['e44', 'e12', 'e2', 'e39', 'e72']]\n",
      "25\n",
      "[['e2', 'e32', 'e2', 'e30']]\n",
      "26\n",
      "[['e2', 'e42', 'e41']]\n",
      "[['e2', 'e42', 'e41'], ['e62', 'e62', 'e62', 'e62', 'e63']]\n",
      "[['e2', 'e42', 'e41'], ['e62', 'e62', 'e62', 'e62', 'e63'], ['e51', 'e51']]\n",
      "[['e2', 'e42', 'e41'], ['e62', 'e62', 'e62', 'e62', 'e63'], ['e51', 'e51'], ['e62']]\n",
      "27\n",
      "[['e2', 'e42', 'e41']]\n",
      "[['e2', 'e42', 'e41'], ['e71', 'e70', 'e65', 'e42', 'e41']]\n",
      "[['e2', 'e42', 'e41'], ['e71', 'e70', 'e65', 'e42', 'e41'], ['e69', 'e69', 'e69', 'e68', 'e67', 'e66', 'e42', 'e41', 'e67', 'e65']]\n",
      "28\n",
      "[['e41', 'e42', 'e65', 'e68', 'e66', 'e65', 'e67', 'e67', 'e66', 'e66']]\n",
      "[['e41', 'e42', 'e65', 'e68', 'e66', 'e65', 'e67', 'e67', 'e66', 'e66'], ['e68', 'e65', 'e71', 'e66', 'e66', 'e42', 'e68', 'e41', 'e68']]\n",
      "[['e41', 'e42', 'e65', 'e68', 'e66', 'e65', 'e67', 'e67', 'e66', 'e66'], ['e68', 'e65', 'e71', 'e66', 'e66', 'e42', 'e68', 'e41', 'e68'], ['e65', 'e41', 'e68', 'e70', 'e66', 'e66', 'e71', 'e42']]\n",
      "29\n",
      "[['e66', 'e53', 'e65', 'e68', 'e66', 'e2', 'e42', 'e65', 'e41']]\n",
      "[['e66', 'e53', 'e65', 'e68', 'e66', 'e2', 'e42', 'e65', 'e41'], ['e66', 'e68']]\n",
      "[['e66', 'e53', 'e65', 'e68', 'e66', 'e2', 'e42', 'e65', 'e41'], ['e66', 'e68'], ['e68', 'e65', 'e2', 'e42', 'e41']]\n",
      "[['e66', 'e53', 'e65', 'e68', 'e66', 'e2', 'e42', 'e65', 'e41'], ['e66', 'e68'], ['e68', 'e65', 'e2', 'e42', 'e41'], ['e41', 'e42', 'e66', 'e66', 'e68', 'e65', 'e70', 'e71', 'e71']]\n"
     ]
    }
   ],
   "source": [
    "sequence_id = 0\n",
    "sequence_list = []\n",
    "for i in range(0, len(sequence_db_grouped)):\n",
    "    \n",
    "    if(sequence_db_grouped.loc[i, 'sequence_id'] != sequence_id):\n",
    "        sequence_id = sequence_db_grouped.loc[i, 'sequence_id']\n",
    "        print(sequence_id)\n",
    "        if(sequence_id != 1):\n",
    "            sequence_list.append(event_list)\n",
    "        event_list = []\n",
    "    event_list.append(sequence_db_grouped.loc[i, 'event_id'])\n",
    "    if(i == len(sequence_db_grouped)-1):\n",
    "        sequence_list.append(event_list)\n",
    "    print(event_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['e1', 'e1', 'e1', 'e1', 'e2', 'e2'],\n",
       "  ['e7',\n",
       "   'e7',\n",
       "   'e7',\n",
       "   'e4',\n",
       "   'e8',\n",
       "   'e4',\n",
       "   'e7',\n",
       "   'e8',\n",
       "   'e9',\n",
       "   'e6',\n",
       "   'e5',\n",
       "   'e6',\n",
       "   'e4',\n",
       "   'e5',\n",
       "   'e5',\n",
       "   'e6',\n",
       "   'e7',\n",
       "   'e7'],\n",
       "  ['e10', 'e1', 'e1', 'e1', 'e1', 'e1', 'e1', 'e11', 'e2', 'e2', 'e1', 'e1']],\n",
       " [['e1', 'e12', 'e2', 'e1']],\n",
       " [['e13', 'e14'], ['e17'], ['e18', 'e18', 'e15', 'e16']],\n",
       " [['e36', 'e1', 'e1', 'e2', 'e11', 'e23', 'e1', 'e2', 'e1'],\n",
       "  ['e11', 'e35', 'e38', 'e21', 'e11', 'e37'],\n",
       "  ['e1',\n",
       "   'e2',\n",
       "   'e39',\n",
       "   'e30',\n",
       "   'e30',\n",
       "   'e30',\n",
       "   'e30',\n",
       "   'e36',\n",
       "   'e11',\n",
       "   'e35',\n",
       "   'e1',\n",
       "   'e11',\n",
       "   'e30']],\n",
       " [['e39', 'e2', 'e1', 'e1'],\n",
       "  ['e39', 'e37', 'e11', 'e21', 'e39', 'e23', 'e40', 'e29', 'e29']],\n",
       " [['e11', 'e12', 'e39', 'e1', 'e1', 'e2']],\n",
       " [['e2', 'e20', 'e1', 'e23', 'e22', 'e20', 'e11', 'e21', 'e1', 'e2'],\n",
       "  ['e24', 'e25', 'e24'],\n",
       "  ['e23', 'e22', 'e20', 'e11']],\n",
       " [['e20', 'e2', 'e1', 'e1'],\n",
       "  ['e29', 'e27', 'e26'],\n",
       "  ['e30'],\n",
       "  ['e23', 'e22', 'e20', 'e11', 'e24', 'e18', 'e31', 'e31']],\n",
       " [['e1', 'e1', 'e2', 'e20'],\n",
       "  ['e23',\n",
       "   'e20',\n",
       "   'e22',\n",
       "   'e11',\n",
       "   'e36',\n",
       "   'e11',\n",
       "   'e34',\n",
       "   'e22',\n",
       "   'e35',\n",
       "   'e34',\n",
       "   'e11',\n",
       "   'e22',\n",
       "   'e20',\n",
       "   'e20'],\n",
       "  ['e1',\n",
       "   'e23',\n",
       "   'e2',\n",
       "   'e20',\n",
       "   'e32',\n",
       "   'e32',\n",
       "   'e30',\n",
       "   'e21',\n",
       "   'e11',\n",
       "   'e20',\n",
       "   'e22',\n",
       "   'e33',\n",
       "   'e1']],\n",
       " [['e29', 'e29', 'e29', 'e29', 'e11', 'e29', 'e29', 'e2', 'e29']],\n",
       " [['e43', 'e43', 'e43', 'e43', 'e43', 'e2'],\n",
       "  ['e24', 'e31', 'e11'],\n",
       "  ['e2'],\n",
       "  ['e44',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e24',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e24',\n",
       "   'e44',\n",
       "   'e24',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e45',\n",
       "   'e2',\n",
       "   'e24',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e24',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e44'],\n",
       "  ['e24', 'e11']],\n",
       " [['e48', 'e41', 'e42']],\n",
       " [['e48', 'e41', 'e48', 'e41', 'e42', 'e2', 'e49', 'e46'],\n",
       "  ['e46', 'e46', 'e46', 'e46', 'e46', 'e46']],\n",
       " [['e21', 'e41', 'e42', 'e1']],\n",
       " [['e30', 'e30', 'e2', 'e2']],\n",
       " [['e1'], ['e32', 'e27', 'e36']],\n",
       " [['e42', 'e41'], ['e47', 'e50', 'e51'], ['e52', 'e50', 'e47']],\n",
       " [['e41', 'e42', 'e39'], ['e53', 'e52']],\n",
       " [['e57', 'e56', 'e55', 'e42', 'e41'],\n",
       "  ['e56', 'e16', 'e15', 'e52', 'e56', 'e56', 'e58']],\n",
       " [['e2', 'e20'], ['e20', 'e56']],\n",
       " [['e36', 'e24', 'e24', 'e24', 'e24', 'e24']],\n",
       " [['e61',\n",
       "   'e36',\n",
       "   'e57',\n",
       "   'e61',\n",
       "   'e57',\n",
       "   'e61',\n",
       "   'e61',\n",
       "   'e60',\n",
       "   'e60',\n",
       "   'e42',\n",
       "   'e59',\n",
       "   'e1',\n",
       "   'e41',\n",
       "   'e57']],\n",
       " [['e64', 'e64', 'e2', 'e39', 'e39']],\n",
       " [['e44', 'e12', 'e2', 'e39', 'e72']],\n",
       " [['e2', 'e32', 'e2', 'e30']],\n",
       " [['e2', 'e42', 'e41'],\n",
       "  ['e62', 'e62', 'e62', 'e62', 'e63'],\n",
       "  ['e51', 'e51'],\n",
       "  ['e62']],\n",
       " [['e2', 'e42', 'e41'],\n",
       "  ['e71', 'e70', 'e65', 'e42', 'e41'],\n",
       "  ['e69', 'e69', 'e69', 'e68', 'e67', 'e66', 'e42', 'e41', 'e67', 'e65']],\n",
       " [['e41', 'e42', 'e65', 'e68', 'e66', 'e65', 'e67', 'e67', 'e66', 'e66'],\n",
       "  ['e68', 'e65', 'e71', 'e66', 'e66', 'e42', 'e68', 'e41', 'e68'],\n",
       "  ['e65', 'e41', 'e68', 'e70', 'e66', 'e66', 'e71', 'e42']],\n",
       " [['e66', 'e53', 'e65', 'e68', 'e66', 'e2', 'e42', 'e65', 'e41'],\n",
       "  ['e66', 'e68'],\n",
       "  ['e68', 'e65', 'e2', 'e42', 'e41'],\n",
       "  ['e41', 'e42', 'e66', 'e66', 'e68', 'e65', 'e70', 'e71', 'e71']]]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['e66', 'e53', 'e65', 'e68', 'e66', 'e2', 'e42', 'e65', 'e41'], ['e66', 'e68'], ['e68', 'e65', 'e2', 'e42', 'e41'], ['e41', 'e42', 'e66', 'e66', 'e68', 'e65', 'e70', 'e71', 'e71']]\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "print(sequence_list[28])\n",
    "print(len(sequence_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputfile = open('sequence_db.txt','w')\n",
    "def seq2idea(sequences):\n",
    "    print(len(sequences))\n",
    "    for sequence in sequences:\n",
    "        for element in sequence:\n",
    "            for event in element:\n",
    "                event = event.split(\"e\")\n",
    "                outputfile.write(event[1] + \" \")\n",
    "            outputfile.write(\"-1 \")\n",
    "        outputfile.write(\"-2 \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '14']\n"
     ]
    }
   ],
   "source": [
    "contoh = \"e14\"\n",
    "contoh_split = contoh.split(\"e\")\n",
    "print(contoh_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "seq2idea(sequence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sequence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import multiprocessing as mp\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "__author__ = \"Jackson Antonio do Prado Lima\"\n",
    "__email__ = \"jacksonpradolima@gmail.com\"\n",
    "__license__ = \"GPL\"\n",
    "__version__ = \"1.0\"\n",
    "\n",
    "\n",
    "class GSP:\n",
    "\n",
    "    def __init__(self, raw_transactions):\n",
    "        self.freq_patterns = []\n",
    "        self._pre_processing(raw_transactions)\n",
    "\n",
    "    def _pre_processing(self, raw_transactions):\n",
    "        '''\n",
    "        Prepare the data\n",
    "        Parameters:\n",
    "                raw_transactions: the data that it will be analysed\n",
    "        '''\n",
    "        self.max_size = max([len(item) for item in raw_transactions])\n",
    "        self.transactions = [tuple(list(i)) for i in raw_transactions]\n",
    "        counts = Counter(chain.from_iterable(raw_transactions))\n",
    "        self.unique_candidates = [tuple([k]) for k, c in counts.items()]\n",
    "\n",
    "    def _is_slice_in_list(self, s, l):\n",
    "        len_s = len(s)  # so we don't recompute length of s on every iteration\n",
    "        return any(s == l[i:len_s + i] for i in range(len(l) - len_s + 1))\n",
    "\n",
    "    def _calc_frequency(self, results, item, minsup):\n",
    "        # The number of times the item appears in the transactions\n",
    "        frequency = len(\n",
    "            [t for t in self.transactions if self._is_slice_in_list(item, t)])\n",
    "        if frequency >= minsup:\n",
    "            results[item] = frequency\n",
    "        return results\n",
    "\n",
    "    def _support(self, items, minsup=0):\n",
    "        '''\n",
    "        The support count (or simply support) for a sequence is defined as\n",
    "        the fraction of total data-sequences that \"contain\" this sequence.\n",
    "        (Although the word \"contains\" is not strictly accurate once we\n",
    "        incorporate taxonomies, it captures the spirt of when a data-sequence\n",
    "        contributes to the support of a sequential pattern.)\n",
    "        Parameters\n",
    "                items: set of items that will be evaluated\n",
    "                minsup: minimum support\n",
    "        '''\n",
    "        results = mp.Manager().dict()\n",
    "        pool = mp.Pool(processes=mp.cpu_count())\n",
    "\n",
    "        for item in items:\n",
    "            pool.apply_async(self._calc_frequency,\n",
    "                             args=(results, item, minsup))\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "        return dict(results)\n",
    "\n",
    "    def _print_status(self, run, candidates):\n",
    "        logging.debug(\"\"\"\n",
    "        Run {}\n",
    "        There are {} candidates.\n",
    "        The candidates have been filtered down to {}.\\n\"\"\"\n",
    "                      .format(run,\n",
    "                              len(candidates),\n",
    "                              len(self.freq_patterns[run - 1])))\n",
    "\n",
    "    def search(self, minsup=0.2):\n",
    "        '''\n",
    "        Run GSP mining algorithm\n",
    "        Parameters\n",
    "                minsup: minimum support\n",
    "        '''\n",
    "        assert (0.0 < minsup) and (minsup <= 1.0)\n",
    "        minsup = len(self.transactions) * minsup\n",
    "\n",
    "        # the set of frequent 1-sequence: all singleton sequences\n",
    "        # (k-itemsets/k-sequence = 1) - Initially, every item in DB is a\n",
    "        # candidate\n",
    "        candidates = self.unique_candidates\n",
    "\n",
    "        # scan transactions to collect support count for each candidate\n",
    "        # sequence & filter\n",
    "        self.freq_patterns.append(self._support(candidates, minsup))\n",
    "\n",
    "        # (k-itemsets/k-sequence = 1)\n",
    "        k_items = 1\n",
    "\n",
    "        self._print_status(k_items, candidates)\n",
    "\n",
    "        # repeat until no frequent sequence or no candidate can be found\n",
    "        while len(self.freq_patterns[k_items - 1]) and (k_items + 1 <= self.max_size):\n",
    "            k_items += 1\n",
    "\n",
    "            # Generate candidate sets Ck (set of candidate k-sequences) -\n",
    "            # generate new candidates from the last \"best\" candidates filtered\n",
    "            # by minimum support\n",
    "            items = np.unique(\n",
    "                list(set(self.freq_patterns[k_items - 2].keys())))\n",
    "\n",
    "            candidates = list(product(items, repeat=k_items))\n",
    "\n",
    "            # candidate pruning - eliminates candidates who are not potentially\n",
    "            # frequent (using support as threshold)\n",
    "            self.freq_patterns.append(self._support(candidates, minsup))\n",
    "\n",
    "            self._print_status(k_items, candidates)\n",
    "        return self.freq_patterns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_95558/1165033458.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhasil03\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGSP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_95558/417512567.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, raw_transactions)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_transactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreq_patterns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pre_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_transactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_transactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_95558/417512567.py\u001b[0m in \u001b[0;36m_pre_processing\u001b[0;34m(self, raw_transactions)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_transactions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_transactions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_transactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_candidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/collections/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, iterable, **kwds)\u001b[0m\n\u001b[1;32m    591\u001b[0m         '''\n\u001b[1;32m    592\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__missing__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/collections/__init__.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, iterable, **kwds)\u001b[0m\n\u001b[1;32m    677\u001b[0m                     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m                 \u001b[0m_count_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "hasil03 = GSP(dataset).search(0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundations\n",
    "### Subsequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is a simple recursive method that checks if subsequence is a subSequence of mainSequence\n",
    "\"\"\"\n",
    "def isSubsequence(mainSequence, subSequence):\n",
    "    subSequenceClone = list(subSequence) # clone the sequence, because we will alter it\n",
    "    return isSubsequenceRecursive(mainSequence, subSequenceClone) #start recursion\n",
    "\n",
    "\"\"\"\n",
    "Function for the recursive call of isSubsequence, not intended for external calls\n",
    "\"\"\"\n",
    "def isSubsequenceRecursive(mainSequence, subSequenceClone, start=0):\n",
    "    # Check if empty: End of recursion, all itemsets have been found\n",
    "    if (not subSequenceClone):\n",
    "        return True\n",
    "    # retrieves element of the subsequence and removes is from subsequence \n",
    "    firstElem = set(subSequenceClone.pop(0))\n",
    "    # Search for the first itemset...\n",
    "    for i in range(start, len(mainSequence)):\n",
    "        if (set(mainSequence[i]).issuperset(firstElem)):\n",
    "            # and recurse\n",
    "            return isSubsequenceRecursive(mainSequence, subSequenceClone, i + 1)\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aSequence = [[\"a\"], [\"b\", \"c\"], [\"d\"], [\"a\", \"e\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isSubsequence(aSequence, [[\"a\"], [\"d\"], [\"e\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isSubsequence(aSequence, [[\"a\"], [\"b\", \"c\"], [\"e\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isSubsequence(aSequence, [[\"a\"], [\"b\", \"d\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(sum([1,2,3,4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length of an itemset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Computes the length of the sequence (sum of the length of the contained itemsets)\n",
    "\"\"\"\n",
    "def sequenceLength(sequence):\n",
    "    return sum(len(i) for i in sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(sequenceLength([[\"a\"], [\"b\", \"c\"], [\"a\"], [\"b\",\"c\",\"d\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support of a sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Computes the support of a sequence in a dataset\n",
    "\"\"\"\n",
    "def countSupport (dataset, candidateSequence):\n",
    "    return sum(1 for seq in dataset if isSubsequence(seq, candidateSequence)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['e1', 'e1', 'e1', 'e1', 'e2', 'e2'],\n",
       "  ['e7',\n",
       "   'e7',\n",
       "   'e7',\n",
       "   'e4',\n",
       "   'e8',\n",
       "   'e4',\n",
       "   'e7',\n",
       "   'e8',\n",
       "   'e9',\n",
       "   'e6',\n",
       "   'e5',\n",
       "   'e6',\n",
       "   'e4',\n",
       "   'e5',\n",
       "   'e5',\n",
       "   'e6',\n",
       "   'e7',\n",
       "   'e7'],\n",
       "  ['e10', 'e1', 'e1', 'e1', 'e1', 'e1', 'e1', 'e11', 'e2', 'e2', 'e1', 'e1']],\n",
       " [['e1', 'e12', 'e2', 'e1']],\n",
       " [['e13', 'e14'], ['e17'], ['e18', 'e18', 'e15', 'e16']],\n",
       " [['e36', 'e1', 'e1', 'e2', 'e11', 'e23', 'e1', 'e2', 'e1'],\n",
       "  ['e11', 'e35', 'e38', 'e21', 'e11', 'e37'],\n",
       "  ['e1',\n",
       "   'e2',\n",
       "   'e39',\n",
       "   'e30',\n",
       "   'e30',\n",
       "   'e30',\n",
       "   'e30',\n",
       "   'e36',\n",
       "   'e11',\n",
       "   'e35',\n",
       "   'e1',\n",
       "   'e11',\n",
       "   'e30']],\n",
       " [['e39', 'e2', 'e1', 'e1'],\n",
       "  ['e39', 'e37', 'e11', 'e21', 'e39', 'e23', 'e40', 'e29', 'e29']],\n",
       " [['e11', 'e12', 'e39', 'e1', 'e1', 'e2']],\n",
       " [['e2', 'e20', 'e1', 'e23', 'e22', 'e20', 'e11', 'e21', 'e1', 'e2'],\n",
       "  ['e24', 'e25', 'e24'],\n",
       "  ['e23', 'e22', 'e20', 'e11']],\n",
       " [['e20', 'e2', 'e1', 'e1'],\n",
       "  ['e29', 'e27', 'e26'],\n",
       "  ['e30'],\n",
       "  ['e23', 'e22', 'e20', 'e11', 'e24', 'e18', 'e31', 'e31']],\n",
       " [['e1', 'e1', 'e2', 'e20'],\n",
       "  ['e23',\n",
       "   'e20',\n",
       "   'e22',\n",
       "   'e11',\n",
       "   'e36',\n",
       "   'e11',\n",
       "   'e34',\n",
       "   'e22',\n",
       "   'e35',\n",
       "   'e34',\n",
       "   'e11',\n",
       "   'e22',\n",
       "   'e20',\n",
       "   'e20'],\n",
       "  ['e1',\n",
       "   'e23',\n",
       "   'e2',\n",
       "   'e20',\n",
       "   'e32',\n",
       "   'e32',\n",
       "   'e30',\n",
       "   'e21',\n",
       "   'e11',\n",
       "   'e20',\n",
       "   'e22',\n",
       "   'e33',\n",
       "   'e1']],\n",
       " [['e29', 'e29', 'e29', 'e29', 'e11', 'e29', 'e29', 'e2', 'e29']],\n",
       " [['e43', 'e43', 'e43', 'e43', 'e43', 'e2'],\n",
       "  ['e24', 'e31', 'e11'],\n",
       "  ['e2'],\n",
       "  ['e44',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e24',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e24',\n",
       "   'e44',\n",
       "   'e24',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e45',\n",
       "   'e2',\n",
       "   'e24',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e24',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e44',\n",
       "   'e44'],\n",
       "  ['e24', 'e11']],\n",
       " [['e48', 'e41', 'e42']],\n",
       " [['e48', 'e41', 'e48', 'e41', 'e42', 'e2', 'e49', 'e46'],\n",
       "  ['e46', 'e46', 'e46', 'e46', 'e46', 'e46']],\n",
       " [['e21', 'e41', 'e42', 'e1']],\n",
       " [['e30', 'e30', 'e2', 'e2']],\n",
       " [['e1'], ['e32', 'e27', 'e36']],\n",
       " [['e42', 'e41'], ['e47', 'e50', 'e51'], ['e52', 'e50', 'e47']],\n",
       " [['e41', 'e42', 'e39'], ['e53', 'e52']],\n",
       " [['e57', 'e56', 'e55', 'e42', 'e41'],\n",
       "  ['e56', 'e16', 'e15', 'e52', 'e56', 'e56', 'e58']],\n",
       " [['e2', 'e20'], ['e20', 'e56']],\n",
       " [['e36', 'e24', 'e24', 'e24', 'e24', 'e24']],\n",
       " [['e61',\n",
       "   'e36',\n",
       "   'e57',\n",
       "   'e61',\n",
       "   'e57',\n",
       "   'e61',\n",
       "   'e61',\n",
       "   'e60',\n",
       "   'e60',\n",
       "   'e42',\n",
       "   'e59',\n",
       "   'e1',\n",
       "   'e41',\n",
       "   'e57']],\n",
       " [['e64', 'e64', 'e2', 'e39', 'e39']],\n",
       " [['e44', 'e12', 'e2', 'e39', 'e72']],\n",
       " [['e2', 'e32', 'e2', 'e30']],\n",
       " [['e2', 'e42', 'e41'],\n",
       "  ['e62', 'e62', 'e62', 'e62', 'e63'],\n",
       "  ['e51', 'e51'],\n",
       "  ['e62']],\n",
       " [['e2', 'e42', 'e41'],\n",
       "  ['e71', 'e70', 'e65', 'e42', 'e41'],\n",
       "  ['e69', 'e69', 'e69', 'e68', 'e67', 'e66', 'e42', 'e41', 'e67', 'e65']],\n",
       " [['e41', 'e42', 'e65', 'e68', 'e66', 'e65', 'e67', 'e67', 'e66', 'e66'],\n",
       "  ['e68', 'e65', 'e71', 'e66', 'e66', 'e42', 'e68', 'e41', 'e68'],\n",
       "  ['e65', 'e41', 'e68', 'e70', 'e66', 'e66', 'e71', 'e42']]]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countSupport(dataset, [[\"e5\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countSupport(dataset, [[\"a\"], [\"b\", \"c\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# AprioriAll\n",
    "### 1 . Candidate Generation\n",
    "#### For a single pair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generates one candidate of length k from two candidates of length (k-1) as used in the AprioriAll algorithm\n",
    "\"\"\"\n",
    "def generateCandidatesForPair(cand1, cand2):\n",
    "    cand1Clone = copy.deepcopy(cand1)\n",
    "    cand2Clone = copy.deepcopy(cand2)\n",
    "    # drop the leftmost item from cand1:\n",
    "    if (len (cand1[0]) == 1):\n",
    "        cand1Clone.pop(0)\n",
    "    else:\n",
    "        cand1Clone[0] = cand1Clone[0][1:]\n",
    "    # drop the rightmost item from cand2:\n",
    "    if (len (cand2[-1]) == 1):\n",
    "        cand2Clone.pop(-1)\n",
    "    else:\n",
    "        cand2Clone[-1] = cand2Clone[-1][:-1]\n",
    "    \n",
    "    # if the result is not the same, then we dont need to join\n",
    "    if not cand1Clone == cand2Clone:\n",
    "        return []\n",
    "    else:\n",
    "        newCandidate = copy.deepcopy(cand1)\n",
    "        if (len (cand2[-1]) == 1):\n",
    "            newCandidate.append(cand2[-1])\n",
    "        else:\n",
    "            newCandidate [-1].extend(cand2[-1][-1])\n",
    "        return newCandidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['a'], ['b', 'c'], ['d', 'e']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidateA = [[\"a\"], [\"b\", \"c\"], [\"d\"]]\n",
    "candidateB = [[\"b\", \"c\"], [\"d\", \"e\"]]\n",
    "generateCandidatesForPair(candidateA, candidateB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['a'], ['b', 'c'], ['d'], ['e']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidateA = [[\"a\"], [\"b\", \"c\"], [\"d\"]]\n",
    "candidateC = [[\"b\", \"c\"], [\"d\"], [\"e\"]]\n",
    "generateCandidatesForPair(candidateA, candidateC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidateA = [[\"a\"], [\"b\", \"c\"], [\"d\"]]\n",
    "candidateD = [[\"a\"], [\"b\", \"c\"], [\"e\"]]\n",
    "generateCandidatesForPair(candidateA, candidateD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For a set of candidates (of the last level):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generates the set of candidates of length k from the set of frequent sequences with length (k-1)\n",
    "\"\"\"\n",
    "def generateCandidates(lastLevelCandidates):\n",
    "    k = sequenceLength(lastLevelCandidates[0]) + 1\n",
    "    if (k == 2):\n",
    "        flatShortCandidates = [item for sublist2 in lastLevelCandidates for sublist1 in sublist2 for item in sublist1]\n",
    "        result = [[[a, b]] for a in flatShortCandidates for b in flatShortCandidates if b > a]\n",
    "        result.extend([[[a], [b]] for a in flatShortCandidates for b in flatShortCandidates])\n",
    "        return result\n",
    "    else:\n",
    "        candidates = []\n",
    "        for i in range(0, len(lastLevelCandidates)):\n",
    "            for j in range(0, len(lastLevelCandidates)):\n",
    "                newCand = generateCandidatesForPair(lastLevelCandidates[i], lastLevelCandidates[j])\n",
    "                if (not newCand == []):\n",
    "                    candidates.append(newCand)\n",
    "        candidates.sort()\n",
    "        return candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example; Lets assume, we know the frequent sequences of level 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastLevelFrequentPatterns = [\n",
    "    [['a', 'b']], \n",
    "    [['b', 'c']], \n",
    "    [['a'], ['b']], \n",
    "    [['a'], ['c']], \n",
    "    [['b'], ['c']],\n",
    "    [['c'], ['b']], \n",
    "    [['c'], ['c']],  \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can compute the generate candidates for level 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['a'], ['b'], ['c']],\n",
       " [['a'], ['b', 'c']],\n",
       " [['a'], ['c'], ['b']],\n",
       " [['a'], ['c'], ['c']],\n",
       " [['a', 'b'], ['c']],\n",
       " [['a', 'b', 'c']],\n",
       " [['b'], ['c'], ['b']],\n",
       " [['b'], ['c'], ['c']],\n",
       " [['b', 'c'], ['b']],\n",
       " [['b', 'c'], ['c']],\n",
       " [['c'], ['b'], ['c']],\n",
       " [['c'], ['b', 'c']],\n",
       " [['c'], ['c'], ['b']],\n",
       " [['c'], ['c'], ['c']]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newCandidates = generateCandidates(lastLevelFrequentPatterns)\n",
    "newCandidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 . Candidate Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Computes all direct subsequence for a given sequence.\n",
    "A direct subsequence is any sequence that originates from deleting exactly one item from any event in the original sequence.\n",
    "\"\"\"\n",
    "def generateDirectSubsequences(sequence):\n",
    "    result = []\n",
    "    for i, itemset in enumerate(sequence):\n",
    "        if (len(itemset) == 1):\n",
    "            sequenceClone = copy.deepcopy(sequence)\n",
    "            sequenceClone.pop(i)\n",
    "            result.append(sequenceClone)\n",
    "        else:\n",
    "            for j in range(len(itemset)):\n",
    "                sequenceClone = copy.deepcopy(sequence)\n",
    "                sequenceClone[i].pop(j)\n",
    "                result.append(sequenceClone)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Prunes the set of candidates generated for length k given all frequent sequence of level (k-1), as done in AprioriAll\n",
    "\"\"\"\n",
    "def pruneCandidates(candidatesLastLevel, candidatesGenerated):\n",
    "    return [cand for cand in candidatesGenerated if all(x in candidatesLastLevel for x in generateDirectSubsequences(cand))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply this on example dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lastLevelFrequentPatterns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_95558/3953961161.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcandidatesPruned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpruneCandidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlastLevelFrequentPatterns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewCandidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcandidatesPruned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lastLevelFrequentPatterns' is not defined"
     ]
    }
   ],
   "source": [
    "candidatesPruned = pruneCandidates(lastLevelFrequentPatterns, newCandidates)\n",
    "candidatesPruned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Count Candidates (and filter not frequent ones):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'candidatesPruned' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_95558/4162297707.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mminSupport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcandidatesCounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcountSupport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcandidatesPruned\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mresultLvl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcandidatesCounts\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mminSupport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mresultLvl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'candidatesPruned' is not defined"
     ]
    }
   ],
   "source": [
    "minSupport = 2\n",
    "candidatesCounts = [(i, countSupport(dataset, i)) for i in candidatesPruned]\n",
    "resultLvl = [(i, count) for (i, count) in candidatesCounts if (count >= minSupport)]\n",
    "resultLvl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put it all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The AprioriAll algorithm. Computes the frequent sequences in a seqeunce dataset for a given minSupport\n",
    "\n",
    "Args:\n",
    "    dataset: A list of sequences, for which the frequent (sub-)sequences are computed\n",
    "    minSupport: The minimum support that makes a sequence frequent\n",
    "    verbose: If true, additional information on the mining process is printed (i.e., candidates on each level)\n",
    "Returns:\n",
    "    A list of tuples (s, c), where s is a frequent sequence, and c is the count for that sequence\n",
    "\"\"\"\n",
    "def apriori(dataset, minSupport, verbose=False):\n",
    "    global numberOfCountingOperations\n",
    "    numberOfCountingOperations = 0\n",
    "    Overall = []\n",
    "    itemsInDataset = sorted(set ([item for sublist1 in dataset for sublist2 in sublist1 for item in sublist2]))\n",
    "    singleItemSequences = [[[item]] for item in itemsInDataset]\n",
    "    singleItemCounts = [(i, countSupport(dataset, i)) for i in singleItemSequences if countSupport(dataset, i) >= minSupport]\n",
    "    Overall.append(singleItemCounts)\n",
    "    print(\"Result, lvl 1: \" + str(Overall[0]))\n",
    "    k = 1\n",
    "    while (True):\n",
    "        if not Overall [k - 1]:\n",
    "            break\n",
    "        # 1. Candidate generation\n",
    "        candidatesLastLevel = [x[0] for x in Overall[k - 1]]\n",
    "        candidatesGenerated = generateCandidates (candidatesLastLevel)\n",
    "        # 2. Candidate pruning (using a \"containsall\" subsequences)\n",
    "        candidatesPruned = [cand for cand in candidatesGenerated if all(x in candidatesLastLevel for x in generateDirectSubsequences(cand))]\n",
    "        # 3. Candidate checking\n",
    "        candidatesCounts = [(i, countSupport(dataset, i)) for i in candidatesPruned]\n",
    "        resultLvl = [(i, count) for (i, count) in candidatesCounts if (count >= minSupport)]\n",
    "        if verbose:\n",
    "            print (\"Candidates generated, lvl \" + str(k + 1) + \": \" + str(candidatesGenerated))\n",
    "            print (\"Candidates pruned, lvl \" + str(k + 1) + \": \" + str(candidatesPruned))\n",
    "            print (\"Result, lvl \" + str(k + 1) + \": \" + str(resultLvl))\n",
    "        Overall.append(resultLvl)\n",
    "        k = k + 1\n",
    "    # \"flatten\" Overall\n",
    "    Overall = Overall [:-1]\n",
    "    Overall = [item for sublist in Overall for item in sublist]\n",
    "    return Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result, lvl 1: [([['e1']], 11), ([['e11']], 9), ([['e12']], 3), ([['e15']], 2), ([['e16']], 2), ([['e18']], 2), ([['e2']], 18), ([['e20']], 4), ([['e21']], 5), ([['e22']], 3), ([['e23']], 5), ([['e24']], 4), ([['e27']], 2), ([['e29']], 3), ([['e30']], 5), ([['e31']], 2), ([['e32']], 3), ([['e35']], 2), ([['e36']], 5), ([['e37']], 2), ([['e39']], 6), ([['e41']], 10), ([['e42']], 10), ([['e44']], 2), ([['e48']], 2), ([['e51']], 2), ([['e52']], 3), ([['e56']], 2), ([['e57']], 2), ([['e65']], 2), ([['e66']], 2), ([['e67']], 2), ([['e68']], 2), ([['e70']], 2), ([['e71']], 2)]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'generateDirectSubsequences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_95558/1649015304.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mapriori\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_95558/3931323995.py\u001b[0m in \u001b[0;36mapriori\u001b[0;34m(dataset, minSupport, verbose)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mcandidatesGenerated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerateCandidates\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcandidatesLastLevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# 2. Candidate pruning (using a \"containsall\" subsequences)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mcandidatesPruned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcand\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcand\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcandidatesGenerated\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcandidatesLastLevel\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerateDirectSubsequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;31m# 3. Candidate checking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mcandidatesCounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcountSupport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcandidatesPruned\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_95558/3931323995.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mcandidatesGenerated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerateCandidates\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcandidatesLastLevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# 2. Candidate pruning (using a \"containsall\" subsequences)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mcandidatesPruned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcand\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcand\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcandidatesGenerated\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcandidatesLastLevel\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerateDirectSubsequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;31m# 3. Candidate checking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mcandidatesCounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcountSupport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcandidatesPruned\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'generateDirectSubsequences' is not defined"
     ]
    }
   ],
   "source": [
    "apriori(dataset, 2, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# PrefixSpan\n",
    "\n",
    "### Project a sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Projects a sequence according to a given prefix, as done in PrefixSpan\n",
    "\n",
    "Args:\n",
    "    sequence: the sequence the projection is built from\n",
    "    prefix: the prefix that is searched for in the sequence\n",
    "    newEvent: if set to True, the first itemset is ignored\n",
    "Returns:\n",
    "    If the sequence does not contain the prefix, then None.\n",
    "    Otherwise, a new sequence starting from the position of the prefix, including the itemset that includes the prefix\n",
    "\"\"\"\n",
    "def projectSequence(sequence, prefix, newEvent):\n",
    "    result = None\n",
    "    for i, itemset in enumerate(sequence):\n",
    "        if result is None:\n",
    "            if (not newEvent) or i > 0:\n",
    "                if (all(x in itemset for x in prefix)):\n",
    "                    result = [list(itemset)]\n",
    "        else:\n",
    "            result.append(copy.copy(itemset))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['b', 'c'], ['a', 'c'], ['c']]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = [[\"a\"], [\"b\", \"c\"], [\"a\", \"c\"], [\"c\"]]\n",
    "projectSequence(seq, [\"b\"], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['a', 'c'], ['c']]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projectSequence(seq, [\"a\", \"c\"], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['a'], ['b', 'c'], ['a', 'c'], ['c']]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projectSequence(seq, [\"a\"], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['a', 'c'], ['c']]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projectSequence(seq, [\"a\"], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Projects a dataset according to a given prefix, as done in PrefixSpan\n",
    "\n",
    "Args:\n",
    "    dataset: the dataset the projection is built from\n",
    "    prefix: the prefix that is searched for in the sequence\n",
    "    newEvent: if set to True, the first itemset is ignored\n",
    "Returns:\n",
    "    A (potentially empty) list of sequences\n",
    "\"\"\"\n",
    "def projectDatabase(dataset, prefix, newEvent):\n",
    "    projectedDB = []\n",
    "    for sequence in dataset:\n",
    "        seqProjected = projectSequence(sequence, prefix, newEvent)\n",
    "        if not seqProjected is None:\n",
    "            projectedDB.append(seqProjected)\n",
    "    return projectedDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetProject = [\n",
    "            [[\"a\"], [\"a\", \"b\", \"c\"], [\"a\", \"c\"], [\"d\"], [\"c\", \"f\"]],\n",
    "            [[\"a\", \"d\"], [\"c\"], [\"b\", \"c\"], [\"a\", \"e\"]],\n",
    "            [[\"e\", \"f\"], [\"a\", \"b\"], [\"d\", \"f\"], [\"d\"], [\"b\"]],\n",
    "            [[\"e\"], [\"g\"], [\"a\", \"f\"], [\"c\"], [\"b\"], [\"c\"]]\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['a', 'b', 'c'], ['a', 'c'], ['d'], ['c', 'f']],\n",
       " [['c'], ['b', 'c'], ['a', 'e']],\n",
       " [['c'], ['b'], ['c']]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projectDatabase(datasetProject, [\"c\"], False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The main algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some more utility functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generates a list of all items that are contained in a dataset\n",
    "\"\"\"\n",
    "def generateItems(dataset):\n",
    "    return sorted(set ([item for sublist1 in dataset for sublist2 in sublist1 for item in sublist2]))\n",
    "\n",
    "\"\"\"\n",
    "Computes a defaultdict that maps each item in the dataset to its support\n",
    "\"\"\"\n",
    "def generateItemSupports(dataset, ignoreFirstEvent=False, prefix=[]):\n",
    "    result = defaultdict(int)\n",
    "    for sequence in dataset:\n",
    "        if ignoreFirstEvent:\n",
    "            sequence = sequence[1:]\n",
    "        cooccurringItems = set()\n",
    "        for itemset in sequence:\n",
    "            if all(x in itemset for x in prefix):\n",
    "                for item in itemset:\n",
    "                    if not item in prefix:\n",
    "                        cooccurringItems.add(item)\n",
    "        for item in cooccurringItems:\n",
    "            result [item] += 1\n",
    "    return sorted(result.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally, the algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The PrefixSpan algorithm. Computes the frequent sequences in a seqeunce dataset for a given minSupport\n",
    "\n",
    "Args:\n",
    "    dataset: A list of sequences, for which the frequent (sub-)sequences are computed\n",
    "    minSupport: The minimum support that makes a sequence frequent\n",
    "Returns:\n",
    "    A list of tuples (s, c), where s is a frequent sequence, and c is the count for that sequence\n",
    "\"\"\"\n",
    "def prefixSpan(dataset, minSupport):\n",
    "    result = []\n",
    "    itemCounts = generateItemSupports(dataset)\n",
    "    for item, count in itemCounts:\n",
    "        if count >= minSupport:\n",
    "            newPrefix = [[item]]\n",
    "            result.append((newPrefix, count))\n",
    "            result.extend(prefixSpanInternal(projectDatabase(dataset, [item], False), minSupport, newPrefix))\n",
    "    return result\n",
    "\n",
    "def prefixSpanInternal(dataset, minSupport, prevPrefixes=[]):\n",
    "    result = []\n",
    "    \n",
    "    # Add a new item to the last element (==same time)\n",
    "    itemCountSameEvent = generateItemSupports(dataset, False, prefix=prevPrefixes[-1])\n",
    "    for item, count in itemCountSameEvent:\n",
    "        if (count >= minSupport) and item > prevPrefixes[-1][-1]:\n",
    "            newPrefix = copy.deepcopy(prevPrefixes)\n",
    "            newPrefix[-1].append(item)\n",
    "            result.append((newPrefix, count))\n",
    "            result.extend(prefixSpanInternal(projectDatabase(dataset, newPrefix[-1], False), minSupport, newPrefix))\n",
    "        \n",
    "    # Add a new event to the prefix\n",
    "    itemCountSubsequentEvents = generateItemSupports(dataset, True)\n",
    "    for item, count in itemCountSubsequentEvents:\n",
    "        if count >= minSupport:\n",
    "            newPrefix = copy.deepcopy(prevPrefixes)\n",
    "            newPrefix.append([item])\n",
    "            result.append((newPrefix, count))\n",
    "            result.extend(prefixSpanInternal(projectDatabase(dataset, [item], True), minSupport, newPrefix))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([['a']], 4),\n",
       " ([['a', 'b']], 2),\n",
       " ([['a', 'b'], ['c']], 2),\n",
       " ([['a', 'b'], ['c'], ['c']], 2),\n",
       " ([['a'], ['b']], 4),\n",
       " ([['a'], ['b', 'c']], 2),\n",
       " ([['a'], ['b'], ['c']], 3),\n",
       " ([['a'], ['c']], 4),\n",
       " ([['a'], ['c'], ['b']], 3),\n",
       " ([['a'], ['c'], ['b'], ['c']], 2),\n",
       " ([['a'], ['c'], ['c']], 4),\n",
       " ([['b']], 4),\n",
       " ([['b', 'c']], 2),\n",
       " ([['b'], ['c']], 3),\n",
       " ([['b'], ['c'], ['c']], 2),\n",
       " ([['c']], 4),\n",
       " ([['c'], ['b']], 3),\n",
       " ([['c'], ['b'], ['c']], 2),\n",
       " ([['c'], ['c']], 4)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefixSpan(dataset, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Filter for closed and maximal patterns\n",
    "### Closed patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Given a list of all frequent sequences and their counts, compute the set of closed frequent sequence (as a list)\n",
    "This is only a very simplistic (naive) implementation for demonstration purposes!\n",
    "\"\"\"\n",
    "def filterClosed(result):\n",
    "    for supersequence, countSeq in copy.deepcopy(result):\n",
    "        for subsequence, countSubSeq in copy.deepcopy(result):\n",
    "            if isSubsequence(supersequence, subsequence) and (countSeq == countSubSeq) and subsequence != supersequence:\n",
    "                result.remove((subsequence, countSubSeq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([['a', 'b'], ['c'], ['c']], 2),\n",
       " ([['a'], ['b']], 4),\n",
       " ([['a'], ['b', 'c']], 2),\n",
       " ([['a'], ['b'], ['c']], 3),\n",
       " ([['a'], ['c'], ['b']], 3),\n",
       " ([['a'], ['c'], ['b'], ['c']], 2),\n",
       " ([['a'], ['c'], ['c']], 4)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = prefixSpan(dataset, 2)\n",
    "filterClosed(result)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximal sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Given a list of all frequent sequences and their counts, compute the set of maximal frequent sequence (as a list)\n",
    "This is only a very naive implementation for demonstration purposes!\n",
    "\"\"\"\n",
    "def filterMaximal(result):\n",
    "    for supersequence, countSeq in copy.deepcopy(result):\n",
    "        for subsequence, countSubSeq in copy.deepcopy(result):\n",
    "            if isSubsequence (supersequence, subsequence) and subsequence != supersequence:\n",
    "                result.remove((subsequence, countSubSeq)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([['a', 'b'], ['c'], ['c']], 2),\n",
       " ([['a'], ['b', 'c']], 2),\n",
       " ([['a'], ['c'], ['b'], ['c']], 2)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = prefixSpan (dataset, 2)\n",
    "filterMaximal(result)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application example: Wikispeedia\n",
    "Now we try to find some sequential patterns in a real world dataset: Wikispeedia\n",
    "\n",
    "First load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "sequences = []\n",
    "\n",
    "# from https://snap.stanford.edu/data/wikispeedia.html\n",
    "for line in csv.reader((row for row in open(\"data/paths_finished.tsv\") if not row.startswith('#')), delimiter='\\t'):\n",
    "    if len(line) == 0:\n",
    "        continue\n",
    "    # for simplicity, let us remove back clicks\n",
    "    seq = line[3].split(\";\")\n",
    "    # for simplicity, let us remove back clicks\n",
    "    seq = [x for x in seq if x != \"<\"]\n",
    "    sequences.append(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert this to the list of list of lists that we use as a dataformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikispeediaData=[]\n",
    "for seq in sequences:\n",
    "    newSeq = []\n",
    "    for item in seq:\n",
    "        newSeq.append([item])\n",
    "    wikispeediaData.append(newSeq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.07 s, sys: 0 ns, total: 4.07 s\n",
      "Wall time: 4.07 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[([['Africa']], 2738),\n",
       " ([['Agriculture']], 1147),\n",
       " ([['Animal']], 1666),\n",
       " ([['Asia']], 1167),\n",
       " ([['Asteroid']], 1171),\n",
       " ([['Asteroid'], ['Viking']], 1043),\n",
       " ([['Atlantic_Ocean']], 1297),\n",
       " ([['Bird']], 1182),\n",
       " ([['Brain']], 1316),\n",
       " ([['Brain'], ['Telephone']], 1043),\n",
       " ([['China']], 1110),\n",
       " ([['Christianity']], 1074),\n",
       " ([['Computer']], 1528),\n",
       " ([['Earth']], 3176),\n",
       " ([['England']], 3261),\n",
       " ([['English_language']], 1414),\n",
       " ([['Europe']], 4303),\n",
       " ([['France']], 1588),\n",
       " ([['Germany']], 1738),\n",
       " ([['Human']], 1604),\n",
       " ([['India']], 1216),\n",
       " ([['Internet']], 1023),\n",
       " ([['Japan']], 1070),\n",
       " ([['Mammal']], 1568),\n",
       " ([['North_America']], 1861),\n",
       " ([['Periodic_table']], 1394),\n",
       " ([['Plant']], 1127),\n",
       " ([['Russia']], 1007),\n",
       " ([['Science']], 1479),\n",
       " ([['Telephone']], 1251),\n",
       " ([['Theatre']], 1034),\n",
       " ([['United_Kingdom']], 3807),\n",
       " ([['United_Nations']], 1050),\n",
       " ([['United_States']], 8675),\n",
       " ([['Viking']], 1192),\n",
       " ([['World_War_II']], 2267),\n",
       " ([['Zebra']], 1041)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time prefixSpan (wikispeediaData, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will take a long time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time apriori(wikispeediaData, 1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
